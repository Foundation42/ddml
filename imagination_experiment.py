"""
Imagination Experiment - Comparing Dream Types for Memory Consolidation

This experiment compares three approaches to preventing catastrophic forgetting:

1. Baseline: Standard network (no protection)
2. Noise Dreams: Pseudo-rehearsal with random noise (current approach)
3. Vivid Dreams: VAE-based generative replay (the upgrade)

The hypothesis: Vivid dreams (generated by the ImaginationCore VAE) should
preserve knowledge better than random noise because they resemble actual
training data rather than static.

Author: Christian Beaumont & Claude
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Subset
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
import json

from mnist_brain import (
    MNISTTripartiteBrain, MNISTBrainConfig,
    TripartitePlayer, PlayerConfig,
    VisualCortex
)
from xor_experiment import ExperimentTracker


@dataclass
class ImaginationExperimentConfig:
    """Configuration for imagination comparison experiment."""
    samples_per_task: int = 3000
    test_samples_per_task: int = 1000
    batch_size: int = 32
    epochs_per_task: int = 3
    seed: int = 42

    # Player settings
    dream_samples: int = 500
    latent_dim: int = 20
    play_epochs: int = 5


class ImaginationExperimentTracker(ExperimentTracker):
    """Tracker for imagination experiments."""
    def __init__(self):
        super().__init__(experiment_name="imagination", personality="vivid_dreams")


def get_split_mnist(config: ImaginationExperimentConfig, task: str):
    """Get MNIST data for a specific task."""
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    train_data = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)
    test_data = torchvision.datasets.MNIST('./data', train=False, download=True, transform=transform)

    if task == "0-4":
        filter_fn = lambda t: t < 5
    else:
        filter_fn = lambda t: t >= 5

    train_idx = [i for i, (_, t) in enumerate(train_data) if filter_fn(t)][:config.samples_per_task]
    test_idx = [i for i, (_, t) in enumerate(test_data) if filter_fn(t)][:config.test_samples_per_task]

    train_loader = DataLoader(Subset(train_data, train_idx), batch_size=config.batch_size, shuffle=True)
    test_loader = DataLoader(Subset(test_data, test_idx), batch_size=config.batch_size)

    return train_loader, test_loader


def evaluate_archive(brain, test_loader, device):
    """Evaluate the Archive on test data."""
    brain.archive.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for x, y in test_loader:
            x, y = x.to(device), y.to(device)
            if x.dim() > 2:
                x = x.view(x.size(0), -1)
            out = brain.archive(x)
            pred = out.argmax(dim=1)
            correct += (pred == y).sum().item()
            total += y.size(0)
    return correct / total


def visualize_dreams(player: TripartitePlayer, tracker: ExperimentTracker, epoch: int):
    """Visualize what the brain is dreaming."""
    if len(player.class_centroids) == 0:
        return

    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
    fig.suptitle(f"What the Brain Dreams (Epoch {epoch})", fontsize=14)

    # Generate dreams for each known class
    player.imagination.eval()
    for class_id, centroid in player.class_centroids.items():
        if class_id >= 10:
            continue

        # Generate a dream from this class centroid
        with torch.no_grad():
            z = centroid.unsqueeze(0) + torch.randn(1, player.player_config.latent_dim, device=player.device) * 0.3
            dream = player.imagination.decode(z)

        dream_img = dream.view(28, 28).cpu().numpy()

        row = class_id // 5
        col = class_id % 5
        axes[row, col].imshow(dream_img, cmap='gray')
        axes[row, col].set_title(f"Dream of '{class_id}'")
        axes[row, col].axis('off')

    # Fill empty slots
    for i in range(10):
        if i not in player.class_centroids:
            row, col = i // 5, i % 5
            axes[row, col].text(0.5, 0.5, "Not learned", ha='center', va='center', fontsize=10)
            axes[row, col].axis('off')

    plt.tight_layout()
    tracker.save_figure(fig, f"dreams_epoch_{epoch}")
    plt.close(fig)


def run_imagination_experiment(config: ImaginationExperimentConfig, verbose: bool = True):
    """
    Run the full imagination comparison experiment.

    Compares:
        1. Core Set Replay (noise dreams fallback)
        2. Vivid Dreams (VAE-based imagination)
    """
    torch.manual_seed(config.seed)
    np.random.seed(config.seed)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Get data
    train_0_4, test_0_4 = get_split_mnist(config, "0-4")
    train_5_9, test_5_9 = get_split_mnist(config, "5-9")

    if verbose:
        print("=" * 70)
        print("IMAGINATION EXPERIMENT: Noise Dreams vs Vivid Dreams")
        print("=" * 70)
        print(f"Device: {device}")
        print(f"Samples per task: {config.samples_per_task}")
        print(f"Dream samples: {config.dream_samples}")
        print()

    # Create two brains with different dream types
    # Brain 1: Standard (uses core set replay, noise dreams as fallback)
    brain_noise = MNISTTripartiteBrain(MNISTBrainConfig())

    # Brain 2: Player with Imagination (vivid dreams)
    player_config = PlayerConfig(
        dream_samples=config.dream_samples,
        latent_dim=config.latent_dim,
        play_epochs=config.play_epochs
    )
    brain_vivid = TripartitePlayer(player_config)

    results = {
        "noise": {"acc_0_4": [], "acc_5_9": []},
        "vivid": {"acc_0_4": [], "acc_5_9": [], "vae_loss": []}
    }

    # ========== PHASE 1: Learn 0-4 ==========
    if verbose:
        print("PHASE 1: Learning digits 0-4")
        print("-" * 40)

    for epoch in range(config.epochs_per_task):
        if verbose:
            print(f"\nEpoch {epoch + 1}/{config.epochs_per_task}")

        # Train both brains
        vae_losses = []
        for x, y in train_0_4:
            brain_noise.wake_step(x, y)
            result = brain_vivid.wake_step(x, y)
            if "vae_loss" in result:
                vae_losses.append(result["vae_loss"])

        # Sleep
        if verbose:
            print("  [Noise Brain] ", end="")
        brain_noise.sleep_and_dream(verbose=verbose)

        if verbose:
            print("  [Vivid Brain] ", end="")
        brain_vivid.sleep_and_dream(verbose=verbose, use_vivid_dreams=True)

        # Evaluate
        acc_noise = evaluate_archive(brain_noise, test_0_4, device)
        acc_vivid = evaluate_archive(brain_vivid, test_0_4, device)

        results["noise"]["acc_0_4"].append(acc_noise)
        results["vivid"]["acc_0_4"].append(acc_vivid)
        if vae_losses:
            results["vivid"]["vae_loss"].append(np.mean(vae_losses))

        if verbose:
            print(f"  Noise Brain (0-4): {acc_noise:.1%}")
            print(f"  Vivid Brain (0-4): {acc_vivid:.1%}")
            if vae_losses:
                print(f"  VAE Loss: {np.mean(vae_losses):.2f}")

    pre_shock_noise = results["noise"]["acc_0_4"][-1]
    pre_shock_vivid = results["vivid"]["acc_0_4"][-1]

    # ========== PHASE 2: The Shock (5-9) ==========
    if verbose:
        print("\n" + "=" * 70)
        print("PHASE 2: THE SHOCK - Learning digits 5-9")
        print("=" * 70)

    for epoch in range(config.epochs_per_task):
        if verbose:
            print(f"\nEpoch {epoch + 1}/{config.epochs_per_task}")

        # Train both brains on new task
        vae_losses = []
        for x, y in train_5_9:
            brain_noise.wake_step(x, y)
            result = brain_vivid.wake_step(x, y)
            if "vae_loss" in result:
                vae_losses.append(result["vae_loss"])

        # Sleep
        if verbose:
            print("  [Noise Brain] ", end="")
        brain_noise.sleep_and_dream(verbose=verbose)

        if verbose:
            print("  [Vivid Brain] ", end="")
        brain_vivid.sleep_and_dream(verbose=verbose, use_vivid_dreams=True)

        # Evaluate on BOTH tasks
        acc_noise_0_4 = evaluate_archive(brain_noise, test_0_4, device)
        acc_noise_5_9 = evaluate_archive(brain_noise, test_5_9, device)
        acc_vivid_0_4 = evaluate_archive(brain_vivid, test_0_4, device)
        acc_vivid_5_9 = evaluate_archive(brain_vivid, test_5_9, device)

        results["noise"]["acc_0_4"].append(acc_noise_0_4)
        results["noise"]["acc_5_9"].append(acc_noise_5_9)
        results["vivid"]["acc_0_4"].append(acc_vivid_0_4)
        results["vivid"]["acc_5_9"].append(acc_vivid_5_9)
        if vae_losses:
            results["vivid"]["vae_loss"].append(np.mean(vae_losses))

        if verbose:
            print(f"  Noise Brain | 0-4: {acc_noise_0_4:.1%} | 5-9: {acc_noise_5_9:.1%}")
            print(f"  Vivid Brain | 0-4: {acc_vivid_0_4:.1%} | 5-9: {acc_vivid_5_9:.1%}")

    # ========== FINAL ANALYSIS ==========
    final_noise_0_4 = results["noise"]["acc_0_4"][-1]
    final_noise_5_9 = results["noise"]["acc_5_9"][-1]
    final_vivid_0_4 = results["vivid"]["acc_0_4"][-1]
    final_vivid_5_9 = results["vivid"]["acc_5_9"][-1]

    noise_forgetting = pre_shock_noise - final_noise_0_4
    vivid_forgetting = pre_shock_vivid - final_vivid_0_4

    summary = {
        "pre_shock_noise": pre_shock_noise,
        "pre_shock_vivid": pre_shock_vivid,
        "final_noise_0_4": final_noise_0_4,
        "final_noise_5_9": final_noise_5_9,
        "final_vivid_0_4": final_vivid_0_4,
        "final_vivid_5_9": final_vivid_5_9,
        "noise_forgetting": noise_forgetting,
        "vivid_forgetting": vivid_forgetting,
        "improvement": noise_forgetting - vivid_forgetting,
        "vivid_brain_state": brain_vivid.get_state()
    }

    results["summary"] = summary

    if verbose:
        print("\n" + "=" * 70)
        print("FINAL RESULTS")
        print("=" * 70)
        print(f"\nNoise Dreams (Core Set):")
        print(f"  Pre-shock (0-4): {pre_shock_noise:.1%}")
        print(f"  Post-shock (0-4): {final_noise_0_4:.1%}")
        print(f"  Post-shock (5-9): {final_noise_5_9:.1%}")
        print(f"  Forgetting: {noise_forgetting:.1%}")
        print()
        print(f"Vivid Dreams (VAE Imagination):")
        print(f"  Pre-shock (0-4): {pre_shock_vivid:.1%}")
        print(f"  Post-shock (0-4): {final_vivid_0_4:.1%}")
        print(f"  Post-shock (5-9): {final_vivid_5_9:.1%}")
        print(f"  Forgetting: {vivid_forgetting:.1%}")
        print()
        print(f"IMPROVEMENT: Vivid dreams reduced forgetting by {summary['improvement']:.1%}")

    return results, brain_vivid


def visualize_imagination_results(
    results: Dict,
    player: TripartitePlayer,
    tracker: ExperimentTracker
):
    """Create comprehensive visualization of imagination experiment."""
    fig = plt.figure(figsize=(16, 12))

    summary = results["summary"]

    # Plot 1: Accuracy over time
    ax1 = fig.add_subplot(2, 2, 1)
    epochs = range(1, len(results["noise"]["acc_0_4"]) + 1)

    ax1.plot(epochs, results["noise"]["acc_0_4"], 'r-o', label="Noise Dreams (0-4)", linewidth=2)
    ax1.plot(epochs, results["vivid"]["acc_0_4"], 'b-o', label="Vivid Dreams (0-4)", linewidth=2)

    # Pad 5-9 accuracy for phase 1
    n_phase1 = len(results["noise"]["acc_0_4"]) - len(results["noise"]["acc_5_9"])
    noise_5_9_padded = [0] * n_phase1 + results["noise"]["acc_5_9"]
    vivid_5_9_padded = [0] * n_phase1 + results["vivid"]["acc_5_9"]

    ax1.plot(epochs, noise_5_9_padded, 'r--s', label="Noise Dreams (5-9)", alpha=0.7)
    ax1.plot(epochs, vivid_5_9_padded, 'b--s', label="Vivid Dreams (5-9)", alpha=0.7)

    ax1.axvline(x=n_phase1 + 0.5, color='black', linestyle='--', label="Task Switch")
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Accuracy")
    ax1.set_title("Memory Retention: Noise vs Vivid Dreams")
    ax1.legend(loc='best')
    ax1.set_ylim(0, 1.05)
    ax1.grid(True, alpha=0.3)

    # Plot 2: Forgetting comparison
    ax2 = fig.add_subplot(2, 2, 2)

    categories = ['Before Switch', 'After Switch']
    noise_vals = [summary["pre_shock_noise"], summary["final_noise_0_4"]]
    vivid_vals = [summary["pre_shock_vivid"], summary["final_vivid_0_4"]]

    x = np.arange(len(categories))
    width = 0.35

    ax2.bar(x - width/2, noise_vals, width, label='Noise Dreams', color='red', alpha=0.7)
    ax2.bar(x + width/2, vivid_vals, width, label='Vivid Dreams', color='blue', alpha=0.7)

    ax2.set_ylabel('Accuracy on 0-4')
    ax2.set_title('The Forgetting Battle')
    ax2.set_xticks(x)
    ax2.set_xticklabels(categories)
    ax2.legend()
    ax2.set_ylim(0, 1.1)

    # Add forgetting annotations
    ax2.annotate(f'↓ {summary["noise_forgetting"]:.0%}',
                xy=(0.2, (noise_vals[0] + noise_vals[1])/2),
                fontsize=12, color='red', fontweight='bold')
    ax2.annotate(f'↓ {summary["vivid_forgetting"]:.0%}',
                xy=(1.2, (vivid_vals[0] + vivid_vals[1])/2),
                fontsize=12, color='blue', fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')

    # Plot 3: VAE Loss over time
    ax3 = fig.add_subplot(2, 2, 3)
    if results["vivid"]["vae_loss"]:
        vae_epochs = range(1, len(results["vivid"]["vae_loss"]) + 1)
        ax3.plot(vae_epochs, results["vivid"]["vae_loss"], 'g-o', linewidth=2)
        ax3.set_xlabel("Epoch")
        ax3.set_ylabel("VAE Loss")
        ax3.set_title("Imagination Learning (VAE Loss)")
        ax3.grid(True, alpha=0.3)

    # Plot 4: Sample Dreams
    ax4 = fig.add_subplot(2, 2, 4)
    ax4.axis('off')

    if len(player.class_centroids) > 0:
        # Create a grid of dreams
        n_classes = min(10, len(player.class_centroids))
        dream_grid = []

        player.imagination.eval()
        for class_id in sorted(player.class_centroids.keys())[:n_classes]:
            centroid = player.class_centroids[class_id]
            with torch.no_grad():
                z = centroid.unsqueeze(0)
                dream = player.imagination.decode(z)
            dream_grid.append(dream.view(28, 28).cpu().numpy())

        # Arrange in a row
        if dream_grid:
            combined = np.hstack(dream_grid)
            ax4_img = fig.add_axes([0.55, 0.1, 0.4, 0.35])
            ax4_img.imshow(combined, cmap='gray')
            ax4_img.set_title(f"What the Brain Imagines (Classes: {list(sorted(player.class_centroids.keys())[:n_classes])})")
            ax4_img.axis('off')

    fig.suptitle("Imagination Experiment: The Power of Vivid Dreams", fontsize=16, y=1.02)
    plt.tight_layout()

    tracker.save_figure(fig, "imagination_results")
    plt.close(fig)


if __name__ == "__main__":
    print("=" * 70)
    print("IMAGINATION EXPERIMENT")
    print("Noise Dreams vs Vivid Dreams (VAE)")
    print("=" * 70)
    print()

    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("Running on CPU")
    print()

    # Configuration
    config = ImaginationExperimentConfig(
        samples_per_task=3000,
        test_samples_per_task=1000,
        epochs_per_task=3,
        batch_size=32,
        dream_samples=500,
        latent_dim=20,
        play_epochs=5,
        seed=42
    )

    # Create tracker
    tracker = ImaginationExperimentTracker()

    # Save config
    with open(tracker.output_dir / "config.json", 'w') as f:
        json.dump({
            "samples_per_task": config.samples_per_task,
            "epochs_per_task": config.epochs_per_task,
            "dream_samples": config.dream_samples,
            "latent_dim": config.latent_dim,
            "play_epochs": config.play_epochs
        }, f, indent=2)

    # Run experiment
    results, player = run_imagination_experiment(config, verbose=True)

    # Save results
    summary = results["summary"]
    summary_text = f"""
IMAGINATION EXPERIMENT RESULTS
==============================
Timestamp: {tracker.timestamp}

CONFIGURATION:
  Samples per task: {config.samples_per_task}
  Epochs per task: {config.epochs_per_task}
  Dream samples: {config.dream_samples}
  VAE latent dim: {config.latent_dim}

NOISE DREAMS (Core Set Replay):
  Pre-shock (0-4): {summary['pre_shock_noise']:.1%}
  Post-shock (0-4): {summary['final_noise_0_4']:.1%}
  Post-shock (5-9): {summary['final_noise_5_9']:.1%}
  Forgetting: {summary['noise_forgetting']:.1%}

VIVID DREAMS (VAE Imagination):
  Pre-shock (0-4): {summary['pre_shock_vivid']:.1%}
  Post-shock (0-4): {summary['final_vivid_0_4']:.1%}
  Post-shock (5-9): {summary['final_vivid_5_9']:.1%}
  Forgetting: {summary['vivid_forgetting']:.1%}

KEY FINDING:
  Vivid dreams {"OUTPERFORMED" if summary['improvement'] > 0 else "underperformed"} noise dreams
  by {abs(summary['improvement']):.1%} in preventing forgetting.

  The ImaginationCore learned to imagine {summary['vivid_brain_state']['imagination']['n_classes']} different classes.
"""

    print("\n" + "=" * 70)
    print(summary_text)

    tracker.save_summary(summary_text)

    # Visualize
    print("Generating visualizations...")
    visualize_imagination_results(results, player, tracker)

    # Save sample dreams
    print("Saving sample dreams...")
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
    fig.suptitle("The Brain's Imagination: What It Dreams")

    player.imagination.eval()
    for idx, (class_id, centroid) in enumerate(sorted(player.class_centroids.items())[:10]):
        with torch.no_grad():
            z = centroid.unsqueeze(0)
            dream = player.imagination.decode(z)
        dream_img = dream.view(28, 28).cpu().numpy()

        row, col = idx // 5, idx % 5
        axes[row, col].imshow(dream_img, cmap='gray')
        axes[row, col].set_title(f"'{class_id}'")
        axes[row, col].axis('off')

    plt.tight_layout()
    tracker.save_figure(fig, "sample_dreams")
    plt.close(fig)

    print(f"\nResults saved to: {tracker.output_dir}")
    print("=" * 70)
